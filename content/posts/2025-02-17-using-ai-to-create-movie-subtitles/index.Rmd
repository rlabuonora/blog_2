---
title: 'Como subtitular pel√≠culas con whisper'
author: ''
date: '2025-02-17'
slug: []
categories: []
tags: []
images: []
---


```{r setup, echo=FALSE}
knitr::opts_chunk$set(eval = FALSE)

```

Estoy tratando de aprender portugu√©s viendo pel√≠culas en portugu√©s. Para aprender, lo ideal es tener los subt√≠tulos en portugu√©s, e ir consultando cuando aparecen palabras nuevas. Esto funciona excelente con las plataformas, donde pude ver Ciudad de Dios, pero se complica cuando hay que recurrir a los corsarios <span style="font-size: 24px;">üè¥‚Äç‚ò†Ô∏è</span> para proveerse de cultura.

Una peli que tengo muchas ganas de ver es O Auto da Compadecida, que solo encontr√© sin subt√≠tulos. Tambi√©n encontr√© otras pel√≠culas interesantes con subt√≠tulos en otros idiomas. Para estos casos se me ocurri√≥ usar un modelo texto a texto para traducir los subt√≠tulos cuando est√°n disponibles en otro idioma. Parece sencillo con la API de GPT, o alguna otra API dedicada para traducci√≥n, pero despu√©s de pensarlo un poco me di cuenta que se pierde un mont√≥n de info entre la palabra que dicen los actores, el subt√≠tulo en una lengua extranjera y la traducci√≥n al portugu√©s de vuelta. 

Entonces se me ocurri√≥ usar un modelo de audio a texto. para transcribir el audio directamente. OpenAI tiene [Whisper](https://cdn.openai.com/papers/whisper.pdf). Como tengo una Mac nueva con GPU, pens√© que el modelo pod√≠a andar bien localmente, pero Whisper no es compatible con la GPU de M1. Entonces, decid√≠ usar una GPU en AWS.

## AWS

EC2 tiene una AMI con Ubuntu preparada para tareas de deep learning. El tipo de instancia es el m√°s barato con GPUs: `g4dn.xlarge`. Tuve un problema con el tope para cada tipo de recurso que podemos pedir, y no me permit√≠a lanzar la instancia porque ped√≠a 4 GPUs y mi l√≠mite era 1. Para levantar ese l√≠mite hay que hacer una solicitud que demora un rato en ser procesada. Comet√≠ el error ü§¶ de pedir un aumento en la cantidad de GPUs en instancias spot en vez de instancias on-demand.

Las instancias spot son instancias que estan disponibles a un precio menor que las on-demand, pero pueden ser terminadas con 2 minutos de aviso. Tambi√©n hay que tener en cuenta que las intancias EC2 incurren en costos mientras est√°n corriendo, y no son baratas, por lo que tenemos que ser cuidadosos y apagarlas cuando no las estamos usando.


Estos son los comandos para configurar la m√°quina con los requerimientos:

```{bash}
# actualizar el OS 
sudo apt update && sudo apt install -y ffmpeg
# instalar las dependencias:
sudo apt install -y python3-venv python3-pip
# crear ambiente virtual 
python3 -m venv whisper_env
# activarlo
source whisper_env/bin/activate
# instalar whisper 
pip install openai-whisper
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

Ahora tenemos que subir el archivo que whisper va a procesar a la instancia. `ffmpeg` puede extraer un archivo mp3 de un archivo de video:

```{bash}
ffmpeg -i o_auto_da_compadecida.mp4 -vn -acodec libmp3lame o_auto_da_compadecida.mp3
```

Para subirlo a la instancia tenemos dos opciones: scp o S3. Copiamos el mp3 con `scp` y 
nos logueamos a la instancia para correr whisper:

```{bash}
whisper o_auto_da_compadecida.mp3 --model medium --language Portuguese --task transcribe --output_format srt

```

Ac√° estoy debiendo un an√°lisis m√°s detallado de cuanto tiempo toma correr esto en la CPU de mi MAC. Tampoco tengo claro cu√°nto me sali√≥ en AWS. 

```{bash}
head -n 10 o_auto_da_compadecida.srt
```

Ahora descargar el archivo srt con scp y a disfrutar de la peli. La transcripci√≥n tiene algunos problemas al principio, pero despu√©s parece dar bien (aunque habr√≠a que mirar la peli completa para verifarlo).


Un problema que tiene esta soluci√≥n es que la GPU es cara. Para optimizar el 
costo en AWS, tengo que parar la instancia cuando no la uso, por lo que ser√≠a
bueno automatizar el proceso de crearla. De hecho, la dej√© prendida una noche sin
usarla y me sali√≥ como 5 USD. Lecci√≥n aprendida.

La otra mejora ser√≠a subir los archivos a S3 en vez de usar `scp`. Como
subir un archivo a S3 es gratis, parece tener sentido subir el archivo de video,
extraer el mp3 en la instancia y luego pasarselo a whisper. Al final no.

# Automatizar AWS

Como no estoy tan ducho en AWS esto me llev√≥ un poquito m√°s de trabajo. La 
soluci√≥n que se me ocurre ser√≠a subir el archivo a S3 y configurar lambda para que
lance la instancia, corra whisper, suba el archivo srt a S3 de vuelta y
cierre la instancia.

Lo primero que hay que resolver bien es el tema de los permisos. La instancia
que corre whisper tiene que tener permisos para leer y escribir en S3. Lo m√°s complejo
es que lambda tiene que tener permisos para crear una instancia __y asignarle los permisos
para leer y escribir a S3__.

La funci√≥n lambda es invocada cuando alguien sube un mp3 al bucket, toma el nombre
del archivo, lanza la instancia y la configura con un script user_data. Este
script:

  - Instala los requerimientos
  - Descarga el archivo de S3
  - Corre whisper con ese archivo
  - Sube el srt a S3
  - Termina la instancia
  
```{python}
import boto3

ec2 = boto3.client("ec2")

AMI_ID = "ami-0a844bb563d863f8c"  
INSTANCE_TYPE = "g4dn.xlarge"  
S3_BUCKET = "INPUT_BUCKET"
S3_OUTPUT_BUCKET = "OUTPUT_BUCKET"

SECURITY_GROUP_ID = "sg-0f5fec4ef93ab7b79"

def lambda_handler(event, context):
    # Extract audio file name from the event
    s3_object = event["Records"][0]["s3"]["object"]["key"]
    base_filename = s3_object.rsplit(".", 1)[0]

    # Launch EC2 instance
    response = ec2.run_instances(
        ImageId=AMI_ID,
        InstanceType=INSTANCE_TYPE,
        KeyName="deep_learning_instance_2",
        SecurityGroupIds=[SECURITY_GROUP_ID], 
        MinCount=1,
        MaxCount=1,
        InstanceMarketOptions={  
            "MarketType": "spot",
            "SpotOptions": {
                "SpotInstanceType": "one-time",  
                "InstanceInterruptionBehavior": "terminate"  
            }
        },
        IamInstanceProfile={'Name': 'EC2-S3-Access'},
        UserData=f'''#!/bin/bash
        apt update && apt install -y ffmpeg git python3-pip
        apt install -y ffmpeg git python3 python3-pip
        # Instalar Whisper AI
        pip3 install openai-whisper

        # Instalar PyTorch con CUDA 
        pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118


        aws s3 cp s3://{S3_BUCKET}/{s3_object} /home/ubuntu/{s3_object}
        whisper /home/ubuntu/{base_filename}.mp3 --language Portuguese --model medium --task transcribe --output_format srt --device cuda
        aws s3 cp /home/ubuntu/{base_filename}.srt s3://{S3_OUTPUT_BUCKET}/{base_filename}.srt
        shutdown -h now
        ''',
        TagSpecifications=[{
            'ResourceType': 'instance',
            'Tags': [{'Key': 'Purpose', 'Value': 'WhisperProcessing'}]
        }]
    )

    instance_id = response['Instances'][0]['InstanceId']
    print(f"EC2 Instance Launched: {instance_id} for file {s3_object}")
    return {"message": f"Processing started for {s3_object}, EC2 instance {instance_id} launched."}

```

No se si configurar esto para automatizar todo vale la pena. Lo cierto es que la soluci√≥n funciona. Ahora hay que ver las pelis a ver que tan bien anda Whisper.

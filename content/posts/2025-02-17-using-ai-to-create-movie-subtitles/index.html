---
title: 'Como subtitular pel√≠culas con whisper'
author: ''
date: '2025-02-17'
slug: []
categories: []
tags: []
images: []
---



<p>Estoy tratando de aprender portugu√©s viendo pel√≠culas en portugu√©s. Para aprender, lo ideal es tener los subt√≠tulos en portugu√©s, e ir consultando cuando aparecen palabras nuevas. Esto funciona excelente con las plataformas, donde pude ver Ciudad de Dios, pero se complica cuando hay que recurrir a los corsarios <span style="font-size: 24px;">üè¥‚Äç‚ò†Ô∏è</span> para proveerse de cultura.</p>
<p>Una peli que tengo muchas ganas de ver es O Auto da Compadecida, que solo encontr√© sin subt√≠tulos. Tambi√©n encontr√© otras pel√≠culas interesantes con subt√≠tulos en otros idiomas. Para estos casos se me ocurri√≥ usar un modelo texto a texto para traducir los subt√≠tulos cuando est√°n disponibles en otro idioma. Parece sencillo con la API de GPT, o alguna otra API dedicada para traducci√≥n, pero despu√©s de pensarlo un poco me di cuenta que se pierde un mont√≥n de info entre la palabra que dicen los actores, el subt√≠tulo en una lengua extranjera y la traducci√≥n al portugu√©s de vuelta.</p>
<p>Entonces se me ocurri√≥ usar [Whisper](<a href="https://cdn.openai.com/papers/whisper.pdf" class="uri">https://cdn.openai.com/papers/whisper.pdf</a> para transcribir el audio directamente. Como tengo una Mac nueva con GPU, pens√© que el modelo pod√≠a andar bien localmente, pero Whisper no es compatible con la GPU de mi MAC, y con la CPU es bastante lento as√≠ que us√© una instancia EC2 en AWS.</p>
<div id="aws" class="section level2">
<h2>AWS</h2>
<p>EC2 tiene una AMI con Ubuntu preparada para tareas de deep learning. El tipo de instancia es el m√°s barato con GPUs: <code>g4dn.xlarge</code>. Una vez lanzada la instancia, actualizamos el OS e instalamos los requerimientos:</p>
<pre class="bash"><code># actualizar el OS 
sudo apt update &amp;&amp; sudo apt install -y ffmpeg
# instalar las dependencias:
sudo apt install -y python3-venv python3-pip
# crear ambiente virtual 
python3 -m venv whisper_env
# activarlo
source whisper_env/bin/activate
# instalar whisper 
pip install openai-whisper
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</code></pre>
<p><code>ffmpeg</code> puede extraer un archivo mp3 de un archivo de video:</p>
<pre class="bash"><code>ffmpeg -i o_auto_da_compadecida.mp4 -vn -acodec libmp3lame o_auto_da_compadecida.mp3</code></pre>
<p>Para subirlo a la instancia tenemos dos opciones: scp o S3. Copiamos el mp3 con <code>scp</code> y
nos logueamos a la instancia para correr whisper:</p>
<pre class="bash"><code>whisper o_auto_da_compadecida.mp3 --model medium --language Portuguese --task transcribe --output_format srt
</code></pre>
<pre class="bash"><code>head -n 10 o_auto_da_compadecida.srt</code></pre>
<p>La transcripci√≥n tiene algunos problemas al principio, pero despu√©s parece dar bien (aunque habr√≠a que mirar la peli completa para verifarlo). Hay que tener en cuenta que esta instancia es cara
(~ 0.5 USD/hora) por lo que hay que pararla cuando no la usomos. La dej√© prendida una noche sin
usarla y me sali√≥ como 5 USD. Lecci√≥n aprendida. Subir los archivos a S3 en vez de usar <code>scp</code> tambi√©n puede ser mejor.</p>
</div>
<div id="automatizar-aws" class="section level1">
<h1>Automatizar AWS</h1>
<p>La soluci√≥n que se me ocurre para automatizar un poco el proceso es subir el
archivo a S3 y configurar lambda para que lance la instancia, corra whisper, suba el archivo srt a S3 de vuelta y termine la instancia.</p>
<p>Lo primero que hay que resolver bien es el tema de los permisos. La instancia
que corre whisper tiene que tener permisos para leer y escribir en S3. Lo m√°s complejo
es que lambda tiene que tener permisos para crear una instancia <strong>y asignarle los permisos
para leer y escribir a S3</strong>.</p>
<p>La funci√≥n lambda es invocada cuando alguien sube un mp3 al bucket, toma el nombre
del archivo, lanza la instancia y la configura con un script user_data. Este
script:</p>
<ul>
<li>Instala los requerimientos</li>
<li>Descarga el archivo de S3</li>
<li>Corre whisper con ese archivo</li>
<li>Sube el srt a S3</li>
<li>Termina la instancia</li>
</ul>
<pre class="python"><code>import boto3

ec2 = boto3.client(&quot;ec2&quot;)

AMI_ID = &quot;ami-0a844bb563d863f8c&quot;  
INSTANCE_TYPE = &quot;g4dn.xlarge&quot;  
S3_BUCKET = &quot;INPUT_BUCKET&quot;
S3_OUTPUT_BUCKET = &quot;OUTPUT_BUCKET&quot;

SECURITY_GROUP_ID = &quot;sg-0f5fec4ef93ab7b79&quot;

def lambda_handler(event, context):
    # Extract audio file name from the event
    s3_object = event[&quot;Records&quot;][0][&quot;s3&quot;][&quot;object&quot;][&quot;key&quot;]
    base_filename = s3_object.rsplit(&quot;.&quot;, 1)[0]

    # Launch EC2 instance
    response = ec2.run_instances(
        ImageId=AMI_ID,
        InstanceType=INSTANCE_TYPE,
        KeyName=&quot;deep_learning_instance_2&quot;,
        SecurityGroupIds=[SECURITY_GROUP_ID], 
        MinCount=1,
        MaxCount=1,
        InstanceMarketOptions={  
            &quot;MarketType&quot;: &quot;spot&quot;,
            &quot;SpotOptions&quot;: {
                &quot;SpotInstanceType&quot;: &quot;one-time&quot;,  
                &quot;InstanceInterruptionBehavior&quot;: &quot;terminate&quot;  
            }
        },
        IamInstanceProfile={&#39;Name&#39;: &#39;EC2-S3-Access&#39;},
        UserData=f&#39;&#39;&#39;#!/bin/bash
        apt update &amp;&amp; apt install -y ffmpeg git python3-pip
        apt install -y ffmpeg git python3 python3-pip
        # Instalar Whisper AI
        pip3 install openai-whisper

        # Instalar PyTorch con CUDA 
        pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

        aws s3 cp s3://{S3_BUCKET}/{s3_object} /home/ubuntu/{s3_object}
        whisper /home/ubuntu/{base_filename}.mp3 --language Portuguese --model medium --task transcribe --output_format srt --device cuda
        aws s3 cp /home/ubuntu/{base_filename}.srt s3://{S3_OUTPUT_BUCKET}/{base_filename}.srt
        shutdown -h now
        &#39;&#39;&#39;,
        TagSpecifications=[{
            &#39;ResourceType&#39;: &#39;instance&#39;,
            &#39;Tags&#39;: [{&#39;Key&#39;: &#39;Purpose&#39;, &#39;Value&#39;: &#39;WhisperProcessing&#39;}]
        }]
    )

    instance_id = response[&#39;Instances&#39;][0][&#39;InstanceId&#39;]
    print(f&quot;EC2 Instance Launched: {instance_id} for file {s3_object}&quot;)
    return {&quot;message&quot;: f&quot;Processing started for {s3_object}, EC2 instance {instance_id} launched.&quot;}</code></pre>
<p>No se si configurar esto para automatizar todo vale la pena. Lo cierto es que la soluci√≥n funciona. Ahora hay que ver las pelis a ver que tan bien anda Whisper.</p>
</div>
